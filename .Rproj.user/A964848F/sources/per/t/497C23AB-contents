---
title: |
  \includegraphics[width=25cm]{EscudoUN.png}  
  \thispagestyle{empty} 
  \vspace*{2.0cm} 
  \textbf{\huge Patrones puntuales para los incendios en California en el 2017}  
  \vspace{5.07cm}
author: |
 |  \Large \textbf{Daniela Arbeláez Montoya}
 |  \Large \textbf{Jefferson Gamboa Betancur}
 |  \Large \textbf{Jean Paul Piedrahita García}
 |  \vspace{5cm}
date: |
  | \small Universidad Nacional de Colombia
  | Ciencias, Escuela de Estadística
  | Medellín, Colombia
  | 2021
documentclass: article
geometry: 
  - top=2cm
  - left=1.8cm
  - right=2cm
  - bottom=2.54cm
fontsize: 12pt
pagestyle: empty
papersize: a4
linestretch: 1.5
linkcolor: blue
links-as-notes: true
lang: "es"
header-includes:
- \usepackage[utf8]{inputenc}
- \setlength{\parindent}{0pt}
- \usepackage{graphicx}
- \pagenumbering{gobble}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
- \usepackage{hyperref}
output: 
    pdf_document: 
      toc: yes
      number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  error = FALSE,
  warning = FALSE,
  tidy = TRUE,
  tidy.opts=list(width.cutoff = 55),
  prompt = TRUE
  )
options(kableExtra.latex.load_packages = FALSE)
require(kableExtra)
```

```{=tex}
\newpage
\pagenumbering{arabic}
\setcounter{page}{2}
\pagestyle{plain}
```

```{r, echo = FALSE}
ITabla <- function(M){
  kbl(M, booktabs = T) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
}
```


# Introducción

California es uno de los lugares que tiene las temporadas de incendios forestales más mortíferas y destructivas. El conjunto de datos contiene la lista de incendios forestales ocurridos en California entre 2013 y 2020; contiene la ubicación donde ocurrieron los incendios forestales, incluido el nombre del condado, los valores de latitud y longitud y también detalles sobre cuándo comenzó el incendio forestal.

Estos datos ayudan a generar información sobre qué lugares de California están bajo amenaza de incendio, a qué hora suelen ocurrir los incendios forestales y qué tan frecuentes y devastadores son.

La base de datos con la que se va realizar el análisis de patrones puntuales fue descargada de [kaggle](https://www.kaggle.com/ananthu017/california-wildfire-incidents-20132020).

Los paquetes a utilizar son los siguientes: 

```{r, echo = TRUE}
library(spatstat)
library(sf)
library(raster)
library(rgdal)
library(tidyverse)
library(maps)
library(plot3D)
library(rgl)
library(stpp)
library(rpanel)
library(KernSmooth)
```

# Análisis descriptivo

Para leer el archivo se utiliza la función **"read_csv"** de la librería **"tidyverse"** de la siguiente manera, visualizando la dimensión de la base de datos con la función *"dim"*.

```{r}
firesCA <- read_csv(file = "https://raw.githubusercontent.com/JeffGB94/Estadistica_Espacial/main/Trabajo%2002/Base/California_Fire_Incidents.csv")

M <- as.data.frame(t(dim(firesCA)))
names(M) <- c("Filas", "Columnas")
ITabla(M)
```

Todos los incendios forestales registrados en la base de datos se encuentran inactivos o han sido contenidos. Debido a la gran cantidad de variables, seleccionamos algunas para visualizar un poco mejor las localizaciones de incendios, tales como:

- **AcresBurned:** representa el número de acres de tierra afectadas por los incendios forestales.

- **ArchiveYear:** año en el cual se desarrolló o se produjo el incendio forestal.

- **Name:** nombre o denominación asignada al incendio forestal.

- **Counties:** nombre del condado en el cual se produjo el incendio forestal.

- **Latitude** y **Longitude** corresponden a las coordenadas geográficas de cada uno de los incendios forestales

```{r, echo = TRUE}
# Selección de variables
firesCA <- firesCA %>% select(AcresBurned, ArchiveYear, Name, 
                              Counties, Latitude, Longitude)
```

```{r, echo=FALSE}
M <- as.data.frame(head(firesCA))
ITabla(M)
```

Para saber el número de incendios que ocurrieron por año, visualizamos el número de registros con la función **table**. Se puede observar que el año 2017 fue el periodo donde más hubo incendios.

```{r, echo = FALSE}
# ¿Cuántos incendios ocurrieron en cada año?
M <- as.data.frame((table(firesCA$ArchiveYear)))
names(M) <- c("Año", "Freq")
ITabla(M)
```

Se desea entonces observar y analizar el patrón de puntos de incendios forestales ocurridos durante el año 2017 en el estado de California. De esta manera realizamos el filtro correspondiente por año de ocurrencia y además, eliminamos aquellas observaciones con errores en sus coordenadas geográficas:

```{r, echo=TRUE}
# Seleccionando el año 2017
firesCA2017 <- firesCA %>% filter(ArchiveYear == 2017, 
                                  Longitude != 0, Latitude != 0)
```

Sin embargo, la base de datos sigue registrando seis observaciones duplicadas de acuerdo a sus coordenadas geográficas. Eliminamos dichas observaciones de la siguiente manera:

```{r, echo=TRUE}
# ¿Hay datos duplicados?: 6 por valores de longitud y latitud
sum(duplicated(firesCA2017 %>% select(Longitude, Latitude)))
firesCA2017 <- firesCA2017[!duplicated(firesCA2017 %>% select(Longitude,
                                                              Latitude)),]
```

La función **project** del paquete **rgdal** ofrece una interfaz con la librería *PROJ.4* de funciones de proyección para datos de posición geográfica. Para poder utilizar esta función debemos extraer las coordenadas de cada uno de los incendios en una matriz. Realizamos la proyección correspondiente de acuerdo a la zona UTM en la cual se encuentra el estado de California y de acuerdo al elipsoide **WGS84** (Sistema Geodésico Mundial).  

```{r, echo = TRUE}
# Seleccionando las coordenadas
coordFiresCA2017 <- firesCA2017 %>% select(Longitude, Latitude) %>% as.matrix()
# Proyección de coordenadas a UTM
pointsFiresCA2017 <- project(coordFiresCA2017, 
                             "+proj=utm +zone=11N +ellps=WGS84") %>% 
  as.data.frame() %>% rename(X = Longitude, Y = Latitude)
```

```{r, echo=FALSE}
pointsFiresCA2017 <- pointsFiresCA2017 %>% filter(!is.infinite(X))
```

## Contorno de California

El paquete **maps** contiene la base de datos **state** que produce un mapa de los estados del territorio continental de los Estados Unidos generado a partir de los datos del Departamento del Censo del mismo país; estos datos contiene las coordenadas geográficas de los polígonos correspondientes a cada uno de los estados.  

```{r, echo = T}
# Base de datos de Estados Unidos
UnitedStates <- map_data("state")
# ¿Qué estados?
names(table(UnitedStates$region))
```

Realizamos el flitro correspondiente al estado de California para obtener el polígono. La función **map_data** del paquete **ggplot2** convierte fácilmente los datos del paquete de **maps** en un marco de datos adecuado para trazar con **ggplot2**. La opción **Mercator** indica meridianos rectos igualmente espaciados, concordantes y rumbos rectos de la brújula.

```{r, echo =T}
# Filtramos para California
California <- UnitedStates %>% filter(region == "california")
ggplot(California, aes(x=long, y=lat)) +
  geom_polygon(fill="white", colour="black") + coord_map("mercator") +
  labs(title = "Estado de California en proyección Mercator",
       x = "Longitud", y = "Latitud") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 12))
```

```{r}
rm(UnitedStates)
```

De la misma manera realizamos la proyección de las coordenadas geográficas en planas de acuerdo a la zona UTM correspondiente al estado de California. 

```{r, echo = T}
# Coordenadas del borde para proyección
coordCA_border <- California %>% select(long, lat) %>% as.matrix()
coordCA_border <- project(coordCA_border, 
                          "+proj=utm +zone=11N +ellps=WGS84") %>% 
  as.data.frame() %>% rename(X = long, Y = lat)
```

Luego de la proyección, podemos crear el objeto **owin** corresponndiente a la ventana de observación para el análisis del patrón de puntos espacial; sin embargo, es posible que algunos puntos o incendios forestales recaigan fuera de dicha ventana de observación, algo que no sería acorde o adecuado para el análisis. Para solucionar este inconveniente utilizamos la función **inside.owin** de la siguiente manera:

```{r}
# Creación del objeto owin a partir del borde
contpolyCA <- owin(poly = data.frame(x = rev(coordCA_border$X), 
                                     y = rev(coordCA_border$Y)))

# ¿Cómo eliminar los puntos que están fuera del contorno?
ok <- inside.owin(x = pointsFiresCA2017$X, y = pointsFiresCA2017$Y, 
                  w = contpolyCA)
pointsFiresCA2017 <- data.frame(X = pointsFiresCA2017$X[ok], 
                                Y = pointsFiresCA2017$Y[ok])
# Creación del objeto ppp a partir del patrón de puntos
FiresCA2017_ppp <- ppp(x = pointsFiresCA2017$X, y = pointsFiresCA2017$Y, 
                       window = contpolyCA)
```

Visualizamos la proyección de los puntos en nuestra ventana de observación

```{r}
ggplot(data = coordCA_border, aes(x = X, y = Y)) + 
  geom_polygon(fill = "white", color = "black") +
  geom_point(data = pointsFiresCA2017, aes(x = X, y = Y), color = "red") +
  labs(title = "Localización de Incendios en California, año 2017") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 12))
```

\newpage

# Procesos puntuales

## Densidad cuadrática (Intensidad)

La intensidad es la densidad promedio de puntos o, en otras palabras, el número esperado de puntos por unidad de área. La intensidad puede ser constante (uniforme) o puede variar de un lugar a otro (no uniforme o no homogéneo).

Un método para evaluar la intensidad es dividir el área de estudio en cuadrantes y contar el número de puntos que caen en cada cuadrante. Si los puntos tienen una intensidad uniforme y son completamente aleatorios, entonces los recuentos de cuadrantes deben ser números aleatorios de Poisson con media constante. Podemos probar esa hipótesis utilizando el estadístico de prueba de bondad de ajuste $\chi^2$.

$$\chi^2 = \sum \dfrac{(Observed - Expected)^2}{Expected}$$

Recordemos que el test chi-cuadrado se emplea para probar un buen ajuste a la distribución de Poisson asumiendo homogeneidad o para probar homogeneidad asumiendo independencia. En R usamos las funciones **quadratcount()** y **quadrat.test()** del paquete **spatstat** para dividir el área de estudio. El siguiente fragmento de código divide el estado de California en una cuadricula 5 filas, 5 columnas y luego se hace el conteo de las localizaciones que caen en cada cuadrante.

```{r, echo=TRUE}
Q <- quadratcount(FiresCA2017_ppp)
```

```{r}
plot(FiresCA2017_ppp, pch = 20, main = "Conteo por cuadrantes", cols = "#00000088")
plot(Q, col = 2, add = TRUE)
```

Se puede calcular la densidad de puntos dentro de cada cuadrante pero cada cuadrante esta en metros cuadrados, por ello para una visualización numérica se decidió pasar las localizaciones en $km^2$ de la siguiente manera:

```{r, echo = TRUE}
# Reescalamiento a kilometros
FiresCA2017_ppp.km <- rescale(FiresCA2017_ppp, 1000, "km")

# Conteo por cuadrantes en km
Q <- quadratcount(FiresCA2017_ppp.km)
# Intensidad
Q.d <- density(FiresCA2017_ppp.km)

par(mfrow = c(1,2), no.readonly = T)
# plot de la densidad
plot(intensity(Q, image = T), 
     main = "Densidad de incendios \n forestales en California", 
     las = 1)
plot(FiresCA2017_ppp.km, pch = 20, cex = 0.6, col = rgb(0,0,0,.5), add = T, 
     cols = "#00000088")
# Intensidad estimada
plot(Q.d, main = "Intensidad Estimada")
contour(Q.d, add = T)
```

```{r}
quadrat.test(Q)
```

Note que $p-value$ es bastante pequeño comparado con un $\alpha = 0.05$, lo que indica que la intensidad no es constante. Este proceso puntual se denomina IPP y su intensidad se puede estimar de forma no paramétrica, por ejemplo, con suavizado del grano (Bivand et al. 2008).

La intensidad espacial estimada para los incendios en California en el año 2017, proporciona una idea de lo que podemos esperar que pase en esa misma región en un futuro no muy lejano.

## Estimación de densidad de Kernel 

Hay diferentes formas de estimar la intensidad para un proceso puntual IPP (No homogéneo), y una de ellas es el **método de suavizamiento por kernel**; en este caso se utiliza una función de kernel bivariada y simétrica.

R actualmente implementa una función de kernel cuartica bidimensional:

$$k(u) = \left\lbrace \begin{array}{c} \frac{3}{\pi} \left( 1- ||u||^2 \right)^2 \quad si \; u \in (-1,1) \\ 0 \qquad \text{en otros casos} \end{array}\right.$$

No existe una regla general para seleccionar el ancho de banda h, que gobierna el nivel de suavizado. Los anchos de banda pequeños dan como resultado mapas más puntiagudos y los anchos de banda grandes dan como resultado un mapa más suave. Es razonable utilizar varios valores según el proceso que se esté considerando y elegir un valor que parezca plausible (Bivand et al. 2008).

## Gráfico de densidad kernel 2D

En este caso se utiliza la función **density.ppp()** del paquete **spatstat** para visualizar gráficos de densidad de kernel. Esta función proporciona una estimación de la función de intensidad del proceso de puntos que generó los datos del patrón de puntos. El argumento **sigma** se toma como la desviación estándar del kernel gaussiano isotrópico, correspondiente al parámetro de ancho de banda. Una pequeña desviación estándar da como resultado una gráfica de densidad más puntiaguda y una gran desviación estándar da como resultado una gráfica de densidad más suave. Los siguientes gráficos corresponden a tres valores distintos en el parámetro **sigma** para observar la diferencia a lo largo de la fila.

```{r}
par(mfrow=c(3,3), mar=c(0,0,1,2))
sigma <- c(50, 200, 1000)
for (j in 1:3){
  ds <- density.ppp(FiresCA2017_ppp.km, sigma=sigma[j])
  plot(ds, main = paste0('Patrón con sigma: ', sigma[j]))
  plot(FiresCA2017_ppp.km, add=T, cex=0.01, regular=F)
  }
```


```{r}
persp(Q.d, main = "Superficie para la intensidad de incendios 2017", 
      theta = -50, phi = 30, shade = 0.75, ticktype = "detailed", xlab = "x", 
      ylab = "y", zlab = "", cex.axis = 0.7, cex.lab = 0.7)
```

# Métodos de probabilidad para modelar la intensidad

Alternativamente a la estimación no paramétrica de la intensidad mediante el suavizado de kernel podemos proponer una función específica para la intensidad cuyos parámetros se estiman maximizando la probabilidad del proceso puntual (Baddeley 2010).

La probabilidad logarítmica para el proceso de Poisson homogéneo con intensidad $\lambda$ es:

$$\log L(\lambda ; x) = n(x) \log \lambda - \lambda \; area(W)$$

donde $n(x)$ es el número de puntos en el conjunto de datos $x$. El estimador de máxima verosimilitud de $\lambda$ y la varianza del estimador son:

$$\widehat{\lambda} = \dfrac{n(x)}{area(W)} \qquad \quad var[\widehat{\lambda}] = \dfrac{\lambda}{area(W)}$$

Para un proceso puntual no homogéneo sabemos entonces que la función de intensidad $\lambda_{\theta}(u)$ depende de un parámetro $\theta$. La log-verosimilitud para $\theta$ es:

$$\log L(\theta ; x) = \sum_{i = 1}^{n} \log \lambda_{\theta}(x_i) - \int_{W} \lambda_{\theta}(u) du$$

donde $\int_{W} \lambda_{\theta}(u) du$ es el número esperado de casos del proceso puntual no homomgéneo con intensidad $\lambda_{\theta}(u)$ en la región $W$.

## Modelo base

Un modelo ajustado como $\lambda_{\theta}((x,y)) = \exp (\theta_0)$.

```{r, echo=TRUE}
base.fires <- ppm(FiresCA2017_ppp.km, ~1)
```

## Modelo log-lineal

Un modelo de Poisson no homogéneo con una intensidad logarítmica lineal en las coordenadas cartesianas, como por ejemplo, $\lambda_{\theta}((x,y)) = \exp (\theta_0 + \theta_1 x + \theta_2 y)$, es ajustado como sigue:

```{r, echo=TRUE}
loglin.fires <- ppm(FiresCA2017_ppp.km, ~x+y)
```

## Modelo log-cuadrático

Un modelo de Poisson no homogéneo con una intensidad logarítmica cuadrática, tal que es cuadrática en $x$ e $y$, como por ejemplo, $\lambda_{\theta}((x,y)) = \exp (\theta_0 + \theta_1 x + \theta_2 y + \theta_3 x^2 + \theta_4 y^2)$

```{r, echo=TRUE}
logquad.fires <- ppm(FiresCA2017_ppp.km, ~polynom(x, y, 2))
```

## Modelo log-polinomial con término de interacción

Un modelo de Poisson no homogéneo con intensidad de log-polinomial con un término de interacción, como $\lambda_{\theta}((x,y)) = \exp (\theta_0 + \theta_1 x + \theta_2 y + \theta_3 x^2 + \theta_4 y^2 + \theta_5 x \cdot y)$, es ajustado como sigue:

```{r, echo=TRUE}
logquadI.fires <- ppm(FiresCA2017_ppp.km, ~polynom(x, y, 2)+I(x*y))
```

# Predicción del modelo

Luego del ajuste de modelos, se continua con el paso de la predicción. El valor devuelto por la función de ajuste de modelo **ppm** es un objeto de clase **ppm** que representa el modelo ajustado. Esto es análogo a otros objetos de modelo en R y, por lo tanto, se pueden aplicar operaciones estándar, tales como **plot()**, **predict()** o **coef()**, entre otras.

Los siguientes gráficos corresponden a la predicción de dos modelos diferentes para el patrón de puntos aleatorio, combinando los comandos **plot()** y **predict()**.

```{r}
par(mfrow=c(1,2),mar=c(0,0,1,2))

plot(predict(loglin.fires), main='Log-linear')
points(FiresCA2017_ppp.km, pch=16, cex=0.2)

plot(predict(logquad.fires), main='log-quadratic')
points(FiresCA2017_ppp.km, pch=16, cex=0.2)
```

# Verificación del modelo 

Después de ajustar un modelo de proceso de puntos a un conjunto de datos de patrones de puntos, deberíamos comprobar que el modelo tenga un buen ajuste y que la suposición de cada componente del modelo sea apropiada.

Un enfoque informal y no probabilístico consiste en examinar los residuos del modelo.

$$Residual = Observed - Fitted$$

Si el modelo tiene un buen ajuste, entonces los residuos deben centrarse alrededor de cero.

La función **diagnostose.ppm()** en el paquete **spatstat** proporciona una forma conveniente de visualizar los residuos calculando un *campo residual suavizado* $s(u)$:

$$s(u) = \widehat{\lambda} (u) - \lambda^{*}(u)$$
donde $\widehat{\lambda} (u)$ es la estimación del kernel no paramétrico de la intensidad, mientras que $\lambda^{*}(u)$ corresponde a una versión suavizada de la estimación paramétrica de la intensidad según el modelo ajustado.

La diferencia $s(u) = \widehat{\lambda} (u) - \lambda^{*}(u)$ debería ser aproximadamente cero si el modelo es verdadero. Se aplica esta función para los siguientes cuatro modelos anteriormente ajustados.

```{r}
par(mfrow=c(1,2),mar=c(1,1,2,2))
diagnose.ppm(loglin.fires, which = "smooth", main = "Smoothed raw residuals \n Log-linear")
diagnose.ppm(logquad.fires, which = "smooth", main = "Smoothed raw residuals \n Log-quadratic")
```


# Análisis basado en la distancia

## Análisis de vecino más cercano promedio

A continuación, calcularemos las distancias promedio de vecino más cercano (ANN) entre la ocurrencia de incendios del año 2017 en California.

Para calcular la distancia promedio del primer vecino más cercano (en acres), se establece $k=1$:

```{r}
mean(nndist(FiresCA2017_ppp.km, k = 1))
```

Para calcular el conjunto de distancia promedio del segundo vecino mas cercano, se usa:

```{r}
mean(nndist(FiresCA2017_ppp.km, k = 2))
```

El parámetro $k$ puede tomar cualquier orden vecino (hasta $n-1$ donde n es el número total de puntos).

A continuación se traza ANN como una función del orden de vecinos para los primeros 150 vecinos mas cercanos.

```{r}
ANN <- apply(nndist(FiresCA2017_ppp.km, k = 1:150), 2, FUN = mean)
plot(ANN ~ eval(1:150), type = "b", main = "Vecinos mas cercanos", las = 1, xlab = "Orden del vecino", ylab = "Distancia media en km")
```

\newpage

# Tecnicas Manuales

## Gráfico de Patterson - Fry

```{r}
# Gráfico de índice de Fry
fryplot(FiresCA2017_ppp.km, main = "Gráfico de Fry")
```

Al realizar el gráfico de Patterson Fry se observa que todos los puntos muestran una alta aglomeración de puntos alrededor del centro, por ello se presume un patrón de agregación.

# Analisis de segundo orden para la incidencia de incendios en California en el 2017

## Función K y F estimada.

```{r}
par(mfrow=c(1,2))
plot(Kest(FiresCA2017_ppp.km), main  = "K-estimada")
plot(Fest(FiresCA2017_ppp.km), main = "F-estimada")
```

- Para la gráfica de K-estimada se ve que debido a que las estimaciones estan por encima de la curva teórica, se puede pensar que se trata de un proceso de agregación.

- Cómo la función F-Estimada las curvas estan por debajo de la curva teórica (Azul) se supone que es un patrón de agregación. 

## Función G estimada y PCF.

```{r}
par(mfrow = c(1,2))
plot(Gest(FiresCA2017_ppp.km), main = "G-estimada")
plot(pcf(FiresCA2017_ppp.km), main = "pair-correlation estimada")
```

- Como las funciones estimadas para la G están por encima de la teórica se presume que el patrón es de agregación.

- Debido a que las estimaciones de la función de correlación por pares se alejan por arriba de la teórica en distancias pequeñas se puede asumir que la hipótesis del patrón puntual es de agregación.

# Test para aleatoriedad completa

## Pointwise Envelopes

```{r, include=FALSE}
K1 <- envelope(FiresCA2017_ppp.km, Kest, nsim = 39, fix.n = TRUE)
P1 <- envelope(FiresCA2017_ppp.km, pcf, nsim = 39, fix.n = TRUE)
F1 <- envelope(FiresCA2017_ppp.km, Fest, nsim = 39, fix.n = TRUE)
G1 <- envelope(FiresCA2017_ppp.km, Gest, nsim = 39, fix.n = TRUE)
```

```{r}
par(mfrow = c(1,2), no.readonly = T)
plot(K1, main = "Envelopes usando K")
plot(P1, main = "Envelopes usando PCF")
```

- Con el test para la aleatoriedad completa se puede concluir que el patrón se aleja por arriba de la curva teórica y además la sombra gris no contiene la curva negra que es la función K-estimada, por ello se asume que es un patrón de agregación. 

- Para la función PCF-estimada a distancias cortas se sobre ajusta a la curva teórica y además las sombras grises no cubren a la función estimada a distancias pequeñas intuyendo un patrón de agregación.

```{r}
par(mfrow = c(1,2))
plot(F1, main = "Envelopes usando F")
plot(G1, main = "Envelopes usando G")
```

- Para la función F el mecánica es al contrario, cuando la función F-estimada esta por debajo de la ajustada se supone que el patrón es de agregación.

- En la función G al tener la curva estima por encima de la teórica se supone que el patrón es de agregación.
